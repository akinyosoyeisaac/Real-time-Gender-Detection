{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-08T19:42:46.023404Z",
     "iopub.status.busy": "2022-09-08T19:42:46.022925Z",
     "iopub.status.idle": "2022-09-08T19:42:52.187781Z",
     "shell.execute_reply": "2022-09-08T19:42:52.186730Z",
     "shell.execute_reply.started": "2022-09-08T19:42:46.023286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL.Image as Image\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T19:42:52.190295Z",
     "iopub.status.busy": "2022-09-08T19:42:52.189653Z",
     "iopub.status.idle": "2022-09-08T19:44:47.096293Z",
     "shell.execute_reply": "2022-09-08T19:44:47.095295Z",
     "shell.execute_reply.started": "2022-09-08T19:42:52.190256Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get directory path to Training dataset\n",
    "train_dir = pathlib.Path('data/Training')\n",
    "# Get a list of all images in the Training dataset\n",
    "train_image_paths = list(train_dir.glob(r'**/*.jpg'))\n",
    "\n",
    "# Get directory path to Validation dataset\n",
    "valid_dir = pathlib.Path('data\\Validation')\n",
    "# Get a list of all images in the Validation dataset\n",
    "valid_image_paths = list(valid_dir.glob(r'**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/Training/female/131422.jpg.jpg'),\n",
       " WindowsPath('data/Training/female/131423.jpg.jpg'),\n",
       " WindowsPath('data/Training/female/131425.jpg.jpg'),\n",
       " WindowsPath('data/Training/female/131427.jpg.jpg'),\n",
       " WindowsPath('data/Training/female/131428.jpg.jpg')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data\\\\Training\\\\female', '131422.jpg.jpg')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.split(str(train_image_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'Training', 'female', '131422.jpg.jpg']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_image_paths[0]).split(os.path.sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:08:43.359141Z",
     "iopub.status.busy": "2022-09-08T20:08:43.358774Z",
     "iopub.status.idle": "2022-09-08T20:08:43.365920Z",
     "shell.execute_reply": "2022-09-08T20:08:43.364829Z",
     "shell.execute_reply.started": "2022-09-08T20:08:43.359111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to extract the labels from image filepath\n",
    "def image_processing(filepath):\n",
    "    labels = [str(filepath[i]).split(os.path.sep)[-2]\n",
    "             for i in range(len(filepath))]\n",
    "    \n",
    "    # Create a DataFrame and input the filepath and labels\n",
    "    filepath = pd.Series(filepath, name = 'Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name = 'Label')\n",
    "    \n",
    "    df = pd.concat([filepath, labels], axis='columns')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:08:44.506624Z",
     "iopub.status.busy": "2022-09-08T20:08:44.506224Z",
     "iopub.status.idle": "2022-09-08T20:08:44.724631Z",
     "shell.execute_reply": "2022-09-08T20:08:44.723297Z",
     "shell.execute_reply.started": "2022-09-08T20:08:44.506593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a train and validation DataFrame\n",
    "train_df = image_processing(train_image_paths)\n",
    "val_df = image_processing(valid_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47009, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:08:46.860944Z",
     "iopub.status.busy": "2022-09-08T20:08:46.860561Z",
     "iopub.status.idle": "2022-09-08T20:08:46.883985Z",
     "shell.execute_reply": "2022-09-08T20:08:46.883031Z",
     "shell.execute_reply.started": "2022-09-08T20:08:46.860913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataFrame with just one label for each label\n",
    "df_unique = train_df.copy().drop_duplicates(subset=['Label']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:08:49.192993Z",
     "iopub.status.busy": "2022-09-08T20:08:49.192617Z",
     "iopub.status.idle": "2022-09-08T20:08:49.199329Z",
     "shell.execute_reply": "2022-09-08T20:08:49.198331Z",
     "shell.execute_reply.started": "2022-09-08T20:08:49.192962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate new images from dataset\n",
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "preprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:08:52.860193Z",
     "iopub.status.busy": "2022-09-08T20:08:52.859814Z",
     "iopub.status.idle": "2022-09-08T20:09:45.752124Z",
     "shell.execute_reply": "2022-09-08T20:09:45.751050Z",
     "shell.execute_reply.started": "2022-09-08T20:08:52.860160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47009 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate images using 'train_df' DataFrame\n",
    "train_images = train_generator.flow_from_dataframe(\n",
    "    dataframe  = train_df,\n",
    "    x_col = 'Filepath',\n",
    "    y_col = 'Label',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 0,\n",
    "    rotation_range = 30,\n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:10:23.391096Z",
     "iopub.status.busy": "2022-09-08T20:10:23.390170Z",
     "iopub.status.idle": "2022-09-08T20:10:40.052478Z",
     "shell.execute_reply": "2022-09-08T20:10:40.051398Z",
     "shell.execute_reply.started": "2022-09-08T20:10:23.391058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11649 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generate images using 'val_df' DataFrame\n",
    "val_images = train_generator.flow_from_dataframe(\n",
    "    dataframe  = val_df,\n",
    "    x_col = 'Filepath',\n",
    "    y_col = 'Label',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'rgb',\n",
    "    class_mode = 'categorical',\n",
    "    batch_size = 32,\n",
    "    shuffle = True,\n",
    "    seed = 0,\n",
    "    rotation_range = 30,\n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:11:06.066060Z",
     "iopub.status.busy": "2022-09-08T20:11:06.065451Z",
     "iopub.status.idle": "2022-09-08T20:11:10.409127Z",
     "shell.execute_reply": "2022-09-08T20:11:10.408092Z",
     "shell.execute_reply.started": "2022-09-08T20:11:06.066025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Use Tensorflow pretrained model\n",
    "pretrained_model = tf.keras.applications.MobileNetV2(\n",
    "input_shape= (224, 224, 3),\n",
    "include_top = False,\n",
    "weights = 'imagenet',\n",
    "pooling = 'avg'\n",
    ")\n",
    "\n",
    "# Freeze weights\n",
    "pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T20:11:16.462892Z",
     "iopub.status.busy": "2022-09-08T20:11:16.462195Z",
     "iopub.status.idle": "2022-09-08T20:11:16.512380Z",
     "shell.execute_reply": "2022-09-08T20:11:16.511472Z",
     "shell.execute_reply.started": "2022-09-08T20:11:16.462856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create weights\n",
    "inputs = pretrained_model.input\n",
    "\n",
    "x = tf.keras.layers.Dense(128, activation = 'relu')(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation = 'relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(2, activation = 'softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T05:56:10.773985Z",
     "iopub.status.busy": "2022-09-08T05:56:10.773594Z",
     "iopub.status.idle": "2022-09-08T06:16:45.748314Z",
     "shell.execute_reply": "2022-09-08T06:16:45.747308Z",
     "shell.execute_reply.started": "2022-09-08T05:56:10.773952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1470/1470 [==============================] - 84876s 58s/step - loss: 0.2885 - accuracy: 0.8815 - val_loss: 0.2307 - val_accuracy: 0.9095\n",
      "Epoch 2/20\n",
      "1470/1470 [==============================] - 3700s 3s/step - loss: 0.2355 - accuracy: 0.9057 - val_loss: 0.2138 - val_accuracy: 0.9131\n",
      "Epoch 3/20\n",
      "1470/1470 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9127"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    validation_data = val_images,\n",
    "    batch_size = 32,\n",
    "    epochs = 20,\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = 2,\n",
    "            restore_best_weights = True\n",
    "        )  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T06:17:25.992346Z",
     "iopub.status.busy": "2022-09-08T06:17:25.991954Z",
     "iopub.status.idle": "2022-09-08T06:17:25.997793Z",
     "shell.execute_reply": "2022-09-08T06:17:25.996498Z",
     "shell.execute_reply.started": "2022-09-08T06:17:25.992311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create labels dictionary\n",
    "labels = {0: 'female',\n",
    "         1: 'male'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T06:17:31.436233Z",
     "iopub.status.busy": "2022-09-08T06:17:31.435854Z",
     "iopub.status.idle": "2022-09-08T06:17:31.443312Z",
     "shell.execute_reply": "2022-09-08T06:17:31.442219Z",
     "shell.execute_reply.started": "2022-09-08T06:17:31.436201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function for image processing and prediction\n",
    "def output(imagepath):\n",
    "    img = image.load_img(imagepath, target_size=(224, 224, 3))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255\n",
    "    img = np.expand_dims(img, [0])\n",
    "    \n",
    "    answer = model.predict(img)[0]\n",
    "    \n",
    "    idx = answer.argmax(axis=-1)\n",
    "    res = labels[idx]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T06:17:32.754689Z",
     "iopub.status.busy": "2022-09-08T06:17:32.753735Z",
     "iopub.status.idle": "2022-09-08T06:17:33.454082Z",
     "shell.execute_reply": "2022-09-08T06:17:33.453157Z",
     "shell.execute_reply.started": "2022-09-08T06:17:32.754640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict gender\n",
    "img = output('../input/gender-classification-dataset/Validation/male/063515.jpg.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-08T06:17:39.714089Z",
     "iopub.status.busy": "2022-09-08T06:17:39.713078Z",
     "iopub.status.idle": "2022-09-08T06:17:39.998859Z",
     "shell.execute_reply": "2022-09-08T06:17:39.997887Z",
     "shell.execute_reply.started": "2022-09-08T06:17:39.714050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('GR.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
